# Hierarchical Category Refinement for Remote Sensing Segmentation A New Task, Benchmark Datasets, and the CG-HCAN Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.8+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/get-started/locally/)

This repository contains the official implementation of **"Hierarchical Category Refinement for Remote Sensing Segmentation: A New Task, Benchmark Datasets, and the CG-HCAN Framework"** published in IEEE Transactions on Geoscience and Remote Sensing.

## ğŸŒŸ Highlights

- **ğŸ“Š New Task**: Introduces hierarchical category refinement for remote sensing segmentation
- **ğŸ—ï¸ Novel Architecture**: CG-HCAN with dual-encoder MiT-B2 and BiCAF fusion
- **ğŸ”— CLIP Integration**: CLIP-guided Graph Neural Network for semantic enhancement
- **ğŸ“ˆ SOTA Performance**: Achieves state-of-the-art results on GID and custom datasets
- **ğŸ”„ Hierarchical Consistency**: Multi-level prediction with hierarchy consistency loss

## ğŸš€ Key Features

### ğŸ—ï¸ Architecture Overview

```
CG-HCAN Framework:
â”œâ”€â”€ Dual-Branch Encoder
â”‚   â”œâ”€â”€ RGB Image Branch (MiT-B2)
â”‚   â””â”€â”€ Mask Branch (Simplified Encoder)
â”œâ”€â”€ BiCAF Fusion Module
â”‚   â”œâ”€â”€ Bidirectional Cross-Attention
â”‚   â”œâ”€â”€ Depthwise Separable Convolution
â”‚   â””â”€â”€ Local Attention Mechanism
â”œâ”€â”€ UNet++ Decoder
â”‚   â”œâ”€â”€ Multi-scale Feature Fusion
â”‚   â””â”€â”€ Dense Skip Connections
â”œâ”€â”€ Semantic Enhancement Module
â”‚   â”œâ”€â”€ CLIP-Guided GNN
â”‚   â””â”€â”€ Adaptive Semantic GNN
â””â”€â”€ Multi-level Prediction Heads
    â”œâ”€â”€ Level-2 Classification Head
    â””â”€â”€ Level-3 Classification Head
```

### ğŸ”¥ Core Innovations

1. **BiCAF Fusion**: Bidirectional Cross-Attention Fusion for effective multi-modal feature integration
2. **CLIP-GNN**: CLIP-guided Graph Neural Network for semantic-aware fine-grained classification
3. **Hierarchy Consistency**: Novel loss function ensuring logical hierarchy between prediction levels
4. **Test-Time Augmentation (TTA)**: Multi-directional flip augmentation for improved inference accuracy

## ğŸ› ï¸ Installation

### Environment Requirements

- Python 3.8+
- PyTorch 1.8+
- CUDA 11.0+ (Recommended)

### Quick Setup

```bash
# Clone the repository
git clone https://github.com/WHUXyb/CG-HCAN.git
cd CG-HCAN

# Install PyTorch (adjust for your CUDA version)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install dependencies
pip install -r requirements.txt

# Install CLIP (optional, for CLIP-GNN)
pip install git+https://github.com/openai/CLIP.git
```

## ğŸ“ Dataset Preparation

### Directory Structure

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ image/          # RGB remote sensing images (.tif)
â”‚   â”œâ”€â”€ label1/         # Level-1 labels (binary masks)
â”‚   â”œâ”€â”€ label2/         # Level-2 labels (multi-class)
â”‚   â””â”€â”€ label3/         # Level-3 labels (fine-grained)
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ image/
â”‚   â””â”€â”€ label1/
â””â”€â”€ model/              # Saved model checkpoints
```

### Supported Datasets

- **GID Dataset**: Gaofen Image Dataset for land use classification
- **Custom Datasets**: Support for custom hierarchical segmentation datasets

## ğŸƒâ€â™‚ï¸ Quick Start

### Training

```bash
# Basic training with BiCAF fusion
python train.py

# Enable CLIP-GNN enhancement
python train.py --use_clip_gnn True

# Custom configuration training
python train.py \
    --batch_size 16 \
    --lr 2e-4 \
    --epochs 100 \
    --bicaf_reduction 8 \
    --use_multi_scale True
```

### Inference

```bash
# Basic inference
python infer.py \
    --model_path ./model/best_model.pth \
    --test_dir ./data/test \
    --output_dir ./results

# Enable Test-Time Augmentation (TTA)
python infer.py \
    --model_path ./model/best_model.pth \
    --test_dir ./data/test \
    --output_dir ./results \
    --use_tta True
```

## âš™ï¸ Configuration

### BiCAF Fusion Configuration

```python
# Bidirectional Cross-Attention Fusion Parameters
USE_BICAF_FUSION = True          # Enable BiCAF fusion
BICAF_REDUCTION_FACTOR = 8       # Channel reduction factor (8/16/32)
USE_MULTI_SCALE_FUSION = True    # Multi-scale fusion
```

### GNN Semantic Enhancement

```python
# Graph Neural Network Configuration
USE_ADAPTIVE_GNN = False         # Basic adaptive GNN
USE_CLIP_GNN = True             # CLIP-guided GNN
CLIP_MODEL_NAME = 'ViT-B/32'    # CLIP model version
```

### Training Hyperparameters

```python
# Core Training Parameters
EPOCHS = 85                      # Training epochs
BATCH_SIZE = 14                  # Batch size
LR = 2e-4                       # Learning rate
WEIGHT_DECAY = 5e-5             # Weight decay
USE_AMP = True                  # Mixed precision training
```

## ğŸ“ˆ Performance Optimization

### 1. Memory Optimization

- **Mixed Precision Training**: Uses AMP to reduce GPU memory usage by 50%
- **Gradient Accumulation**: Simulate large batch sizes on small GPUs
- **Local Attention**: BiCAF uses 8Ã—8 block partitioning, reducing complexity from O(NÂ²) to O(N)

### 2. Training Stability

- **Gradient Clipping**: Prevents gradient explosion
- **Learning Rate Scheduling**: OneCycleLR strategy
- **Early Stopping**: Prevents overfitting

### 3. Inference Acceleration

- **Model Quantization**: Support for INT8 quantized inference
- **TensorRT Optimization**: GPU-accelerated inference
- **Batch Inference**: Support for large-scale data processing

## ğŸ¯ Applications

### Land Use Classification

- Urban Planning
- Environmental Monitoring
- Agricultural Management
- Natural Resource Survey

### Ecological Environment Monitoring

- Forest Cover Analysis
- Wetland Protection
- Desertification Monitoring
- Biodiversity Assessment

## ğŸ“‚ Project Structure

```
CG-HCAN/
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ model.py                  # Core network architecture
â”œâ”€â”€ train.py                  # Training script
â”œâ”€â”€ infer.py                  # Inference script
â”œâ”€â”€ dataProcess.py           # Data processing utilities
â”œâ”€â”€ DataAugmentation.py      # Data augmentation module
â”œâ”€â”€ hierarchy_dict.py        # Category hierarchy mapping
â”œâ”€â”€ cal_acc2.py             # Accuracy calculation tools
â”œâ”€â”€ configs/                 # Configuration files
â”‚   â”œâ”€â”€ gid_config.py       # GID dataset config
â”‚   â””â”€â”€ forest_config.py    # Forest dataset config
â”œâ”€â”€ scripts/                 # Run scripts
â”‚   â”œâ”€â”€ train_gid.sh        # GID training script
â”‚   â””â”€â”€ eval_models.sh      # Model evaluation script
â””â”€â”€ docs/                   # Detailed documentation
    â”œâ”€â”€ INSTALL.md          # Installation guide
    â”œâ”€â”€ DATASETS.md         # Dataset description
    â””â”€â”€ MODEL_DETAILS.md    # Model details
```

## ğŸ“‹ TODO List

- [ ] Support for more pre-trained backbone networks
- [ ] Real-time inference demo
- [ ] More benchmark datasets
- [ ] Pre-trained model downloads
- [ ] Distributed training support
- [ ] Web visualization interface

## ğŸ“„ Citation

If this work is helpful for your research, please consider citing our paper:

```bibtex
@article{xiong2024hierarchical,
  title={Hierarchical Category Refinement for Remote Sensing Segmentation: A New Task, Benchmark Datasets, and the CG-HCAN Framework},
  author={Xiong, Y. and Zhang, B. and Li, S.},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}
```

## ğŸ“ Contact

- **Authors**: Xiong et al.
- **Email**: userxyb@whu.edu.cn
- **Institution**: Wuhan University

## ğŸ“œ License

This project is released under the [MIT License](LICENSE).

## ğŸ¤ Contributing

We welcome Issues and Pull Requests! Please refer to the contributing guidelines for details.

## ğŸ”— Related Links

- [Paper Preprint](https://arxiv.org/abs/xxxx.xxxxx)
- [Project Homepage](https://whuxxyb.github.io/CG-HCAN)
- [Dataset Download](https://pan.baidu.com/s/xxxxxxxxx)
- [Pre-trained Models](https://github.com/WHUXyb/CG-HCAN/releases)

---

â­ If this project helps you, please give us a star!

## Acknowledgments

We thank the contributors to the open-source libraries that made this work possible:
- [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)
- [OpenAI CLIP](https://github.com/openai/CLIP)
- [PyTorch](https://pytorch.org/)
