# Hierarchical Category Refinement for Remote Sensing Segmentation A New Task, Benchmark Datasets, and the CG-HCAN Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.8+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/get-started/locally/)

This repository contains the official implementation of **"Hierarchical Category Refinement for Remote Sensing Segmentation: A New Task, Benchmark Datasets, and the CG-HCAN Framework"** submitted to IEEE Transactions on Geoscience and Remote Sensing.

## ğŸŒŸ Highlights

- **ğŸ“Š New Task**: Introduces hierarchical category refinement for remote sensing segmentation
- **ğŸ—ï¸ Novel Architecture**: CG-HCAN with dual-encoder framework and BiCAF fusion module
- **ğŸ”— CLIP Integration**: CLIP-guided Graph Neural Network for semantic-aware classification
- **ğŸ“ˆ Superior Performance**: Comprehensive evaluation on GID dataset and custom forest dataset
- **ğŸ”„ Hierarchical Consistency**: Multi-level prediction ensuring logical hierarchy constraints

## ğŸš€ Key Features

### ğŸ—ï¸ Architecture Overview

```
CG-HCAN Framework:
â”œâ”€â”€ Dual-Branch Encoder
â”‚   â”œâ”€â”€ RGB Image Branch (MiT-B2)
â”‚   â””â”€â”€ Mask Branch (Simplified Encoder)
â”œâ”€â”€ BiCAF Fusion Module
â”‚   â”œâ”€â”€ Bidirectional Cross-Attention Mechanism
â”‚   â”œâ”€â”€ Channel Reduction and Feature Enhancement
â”‚   â””â”€â”€ Spatial Attention Integration
â”œâ”€â”€ UNet++ Decoder
â”‚   â”œâ”€â”€ Multi-scale Feature Aggregation
â”‚   â””â”€â”€ Dense Skip Connections
â”œâ”€â”€ CLIP-Guided Graph Neural Network
â”‚   â”œâ”€â”€ Category Embedding with CLIP ViT-B/32
â”‚   â””â”€â”€ Graph-based Semantic Enhancement
â””â”€â”€ Hierarchical Prediction Heads
    â”œâ”€â”€ Level-2 Land Use Classification
    â””â”€â”€ Level-3 Fine-grained Classification
```

### ğŸ”¥ Core Innovations

1. **Hierarchical Category Refinement**: Novel task formulation addressing multi-level land use classification
2. **BiCAF Fusion**: Bidirectional Cross-Attention Fusion for effective dual-branch feature integration  
3. **CLIP-GNN Enhancement**: CLIP-guided Graph Neural Network for semantic-aware classification refinement
4. **Hierarchy Consistency Loss**: Mathematical constraint ensuring logical relationships between hierarchical levels

## ğŸ› ï¸ Installation

### Environment Requirements

- Python 3.8+
- PyTorch 1.8+
- CUDA 11.0+ (Recommended)

### Quick Setup

```bash
# Clone the repository
git clone https://github.com/WHUXyb/CG-HCAN.git
cd CG-HCAN

# Install PyTorch (adjust for your CUDA version)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install dependencies
pip install -r requirements.txt

# Install CLIP (optional, for CLIP-GNN)
pip install git+https://github.com/openai/CLIP.git
```

## ğŸ“ Dataset Preparation

### Directory Structure

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ image/          # RGB remote sensing images (.tif)
â”‚   â”œâ”€â”€ label1/         # Level-1 labels (binary masks)
â”‚   â”œâ”€â”€ label2/         # Level-2 labels (multi-class)
â”‚   â””â”€â”€ label3/         # Level-3 labels (fine-grained)
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ image/
â”‚   â””â”€â”€ label1/
â””â”€â”€ model/              # Saved model checkpoints
```

### Benchmark Datasets

- **GID Dataset**: Gaofen Image Dataset with hierarchical land use annotation
  - 150 high-resolution Gaofen-2 satellite images (6,800Ã—7,200 pixels)
  - Hierarchical labels: Level-1 (15 classes) â†’ Level-2 (15 classes) â†’ Level-3 (37 classes)
- **Forest Dataset**: Custom forest classification dataset
  - Multi-temporal forest monitoring with hierarchical structure
  - Specialized for forest type and health assessment

## ğŸƒâ€â™‚ï¸ Quick Start

### Training

```bash
# 5-fold cross-validation training (paper setup)
python train.py

# Training with CLIP-GNN enhancement
python train.py --use_clip_gnn True --clip_model ViT-B/32

# Custom configuration for different datasets
python train.py \
    --epochs 85 \
    --batch_size 14 \
    --lr 2e-4 \
    --weight_decay 5e-5 \
    --bicaf_reduction 8 \
    --use_amp True
```

### Inference

```bash
# Hierarchical inference (Level-2 and Level-3)
python infer.py \
    --model_path ./model/fold0_best_model.pth \
    --test_dir ./data/test \
    --output_dir ./results

# Inference with Test-Time Augmentation
python infer.py \
    --model_path ./model/fold0_best_model.pth \
    --test_dir ./data/test \
    --output_dir ./results \
    --use_tta True \
    --model_version detailed
```

## âš™ï¸ Configuration

### BiCAF Fusion Configuration

```python
# Bidirectional Cross-Attention Fusion Parameters
USE_BICAF_FUSION = True          # Enable BiCAF fusion
BICAF_REDUCTION_FACTOR = 8       # Channel reduction factor (8/16/32)
USE_MULTI_SCALE_FUSION = True    # Multi-scale fusion
```

### GNN Semantic Enhancement

```python
# Graph Neural Network Configuration
USE_ADAPTIVE_GNN = False         # Basic adaptive GNN
USE_CLIP_GNN = True             # CLIP-guided GNN
CLIP_MODEL_NAME = 'ViT-B/32'    # CLIP model version
```

### Training Configuration

```python
# Experimental Setup (following paper)
EPOCHS = 85                      # Training epochs
BATCH_SIZE = 14                  # Batch size per GPU
LEARNING_RATE = 2e-4            # Initial learning rate
WEIGHT_DECAY = 5e-5             # L2 regularization
OPTIMIZER = 'AdamW'             # AdamW optimizer
LR_SCHEDULER = 'OneCycleLR'     # Learning rate scheduling
CROSS_VALIDATION = 5            # 5-fold cross-validation
MIXED_PRECISION = True          # FP16 mixed precision training
```

## ğŸ“ˆ Performance Optimization

### 1. Memory Optimization

- **Mixed Precision Training**: Uses AMP to reduce GPU memory usage by 50%
- **Gradient Accumulation**: Simulate large batch sizes on small GPUs
- **Local Attention**: BiCAF uses 8Ã—8 block partitioning, reducing complexity from O(NÂ²) to O(N)

### 2. Training Stability

- **Gradient Clipping**: Prevents gradient explosion
- **Learning Rate Scheduling**: OneCycleLR strategy
- **Early Stopping**: Prevents overfitting

### 3. Inference Acceleration

- **Model Quantization**: Support for INT8 quantized inference
- **TensorRT Optimization**: GPU-accelerated inference
- **Batch Inference**: Support for large-scale data processing

## ğŸ¯ Applications

### Land Use Classification

- Urban Planning
- Environmental Monitoring
- Agricultural Management
- Natural Resource Survey

### Ecological Environment Monitoring

- Forest Cover Analysis
- Wetland Protection
- Desertification Monitoring
- Biodiversity Assessment

## ğŸ“‚ Project Structure

```
CG-HCAN/
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ model.py                  # Core network architecture
â”œâ”€â”€ train.py                  # Training script
â”œâ”€â”€ infer.py                  # Inference script
â”œâ”€â”€ dataProcess.py           # Data processing utilities
â”œâ”€â”€ DataAugmentation.py      # Data augmentation module
â”œâ”€â”€ hierarchy_dict.py        # Category hierarchy mapping
â”œâ”€â”€ cal_acc2.py             # Accuracy calculation tools
â”œâ”€â”€ configs/                 # Configuration files
â”‚   â”œâ”€â”€ gid_config.py       # GID dataset config
â”‚   â””â”€â”€ forest_config.py    # Forest dataset config
â”œâ”€â”€ scripts/                 # Run scripts
â”‚   â”œâ”€â”€ train_gid.sh        # GID training script
â”‚   â””â”€â”€ eval_models.sh      # Model evaluation script
â””â”€â”€ docs/                   # Detailed documentation
    â”œâ”€â”€ INSTALL.md          # Installation guide
    â”œâ”€â”€ DATASETS.md         # Dataset description
    â””â”€â”€ MODEL_DETAILS.md    # Model details
```

## ğŸ“‹ TODO List

- [ ] Support for more pre-trained backbone networks
- [ ] Real-time inference demo
- [ ] More benchmark datasets
- [ ] Pre-trained model downloads
- [ ] Distributed training support
- [ ] Web visualization interface

## ğŸ“„ Citation

If this work is helpful for your research, please consider citing our paper:

```bibtex
@article{xiong2024hierarchical,
  title={Hierarchical Category Refinement for Remote Sensing Segmentation: A New Task, Benchmark Datasets, and the CG-HCAN Framework},
  author={Xiong, Yuanbo and Zhang, Bowen and Li, Songtao and Wang, Jianwei and Liu, Mingming},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  note={Under Review}
}
```

## ğŸ“ Contact

- **Corresponding Author**: Yuanbo Xiong
- **Email**: userxyb@whu.edu.cn
- **Institution**: School of Resource and Environmental Sciences, Wuhan University
- **Address**: 129 Luoyu Road, Wuhan 430079, China

## ğŸ“œ License

This project is released under the [MIT License](LICENSE).

## ğŸ¤ Contributing

We welcome Issues and Pull Requests! Please refer to the contributing guidelines for details.

## ğŸ”— Related Links

- [Paper Preprint](https://arxiv.org/abs/xxxx.xxxxx)
- [Project Homepage](https://whuxxyb.github.io/CG-HCAN)
- [Dataset Download](https://pan.baidu.com/s/xxxxxxxxx)
- [Pre-trained Models](https://github.com/WHUXyb/CG-HCAN/releases)

---

â­ If this project helps you, please give us a star!

## Acknowledgments

We thank the contributors to the open-source libraries that made this work possible:
- [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)
- [OpenAI CLIP](https://github.com/openai/CLIP)
- [PyTorch](https://pytorch.org/)
