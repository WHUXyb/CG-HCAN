# -*- coding: utf-8 -*-
"""
Created on Wed May 14 16:16:09 2025

@author: xiong
"""

import cv2
import numpy as np
from pathlib import Path
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
import warnings, time
import hierarchy_dict  # å¯¼å…¥å±‚æ¬¡å…³ç³»æ˜ å°„
warnings.filterwarnings("ignore")

# ------------ è·¯å¾„é…ç½® ------------
# äºŒçº§æ ‡ç­¾è¯„ä¼°
label_dir_level2 = Path(r"./data/test/label2")
pred_dir_level2  = Path(r"./results/result_level2")
# ä¸‰çº§æ ‡ç­¾è¯„ä¼°
label_dir_level3 = Path(r"./data/test/label3")
pred_dir_level3  = Path(r"./results/result_level3")

max_workers = 14          # æ ¹æ®ç¡¬ä»¶è°ƒæ•´
# ----------------------------------

def pair_paths(lbl_dir, prd_dir, exts=[".png", ".tif", ".jpg"]):
    lbls = []
    for ext in exts:
        lbls += list(lbl_dir.glob(f"*{ext}"))
    lbls = sorted(lbls)
    prds = [prd_dir / p.name for p in lbls]
    return lbls, prds

def calculate_hierarchical_consistency(pred_level3_dir, pred_level2_dir, level3_labels):
    """
    è®¡ç®—å±‚æ¬¡ä¸€è‡´æ€§æŒ‡æ ‡ï¼ˆHierarchical Consistencyï¼‰
    
    Args:
        pred_level3_dir: ä¸‰çº§é¢„æµ‹ç»“æœç›®å½•
        pred_level2_dir: äºŒçº§é¢„æµ‹ç»“æœç›®å½•
        level3_labels: ä¸‰çº§æ ‡ç­¾æ–‡ä»¶åˆ—è¡¨
    
    Returns:
        float: å±‚æ¬¡ä¸€è‡´æ€§æŒ‡æ ‡ (0-1ä¹‹é—´)
    """
    print(f"\n{'='*20} è®¡ç®—å±‚æ¬¡ä¸€è‡´æ€§æŒ‡æ ‡ {'='*20}")
    
    # åˆ›å»ºæ˜ å°„æ•°ç»„ä»¥æé«˜æ•ˆç‡
    max_label = max(hierarchy_dict.map_3_to_2.keys())
    mapping_array = np.zeros(max_label + 1, dtype=np.int32)
    for k, v in hierarchy_dict.map_3_to_2.items():
        mapping_array[k] = v
    
    total_pixels = 0
    consistent_pixels = 0
    processed_files = 0
    
    for label_path in tqdm(level3_labels, desc="è®¡ç®—å±‚æ¬¡ä¸€è‡´æ€§"):
        pred3_path = pred_level3_dir / label_path.name
        pred2_path = pred_level2_dir / label_path.name
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not pred3_path.exists() or not pred2_path.exists():
            print(f"è­¦å‘Š: é¢„æµ‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ {label_path.name}")
            continue
        
        # è¯»å–é¢„æµ‹ç»“æœ
        pred3 = cv2.imread(str(pred3_path), cv2.IMREAD_GRAYSCALE)
        pred2 = cv2.imread(str(pred2_path), cv2.IMREAD_GRAYSCALE)
        
        if pred3 is None or pred2 is None:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒï¼Œè·³è¿‡ {label_path.name}")
            continue
            
        if pred3.shape != pred2.shape:
            print(f"è­¦å‘Š: å›¾åƒå°ºå¯¸ä¸åŒ¹é…ï¼Œè·³è¿‡ {label_path.name}")
            continue
        
        # å°†ä¸‰çº§é¢„æµ‹æ˜ å°„åˆ°äºŒçº§
        pred3_mapped = mapping_array[pred3]
        
        # è®¡ç®—ä¸€è‡´æ€§
        consistent = (pred3_mapped == pred2)
        consistent_pixels += np.sum(consistent)
        total_pixels += pred3.size
        processed_files += 1
    
    if total_pixels == 0:
        print("é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒå¯¹è¿›è¡Œå±‚æ¬¡ä¸€è‡´æ€§è®¡ç®—")
        return 0.0
    
    hc_score = consistent_pixels / total_pixels
    print(f"å¤„ç†æ–‡ä»¶æ•°: {processed_files}")
    print(f"æ€»åƒç´ æ•°: {total_pixels:,}")
    print(f"ä¸€è‡´åƒç´ æ•°: {consistent_pixels:,}")
    print(f"å±‚æ¬¡ä¸€è‡´æ€§ (HC): {hc_score:.4f}")
    
    return hc_score

def calculate_hierarchical_distance_weighted_accuracy(pred_level3_dir, label_level3_dir, level3_labels):
    """
    è®¡ç®—å±‚æ¬¡è·ç¦»åŠ æƒå‡†ç¡®ç‡ (Hierarchical Distance Weighted Accuracy, HDWA)
    
    æ ¹æ®é¢„æµ‹é”™è¯¯åœ¨å±‚æ¬¡æ ‘ä¸­çš„è·ç¦»æ¥åŠ æƒï¼Œè·¨å¤§ç±»é”™è¯¯æ¯”ç±»å†…é”™è¯¯æƒ©ç½šæ›´é‡
    
    Args:
        pred_level3_dir: ä¸‰çº§é¢„æµ‹ç»“æœç›®å½•
        label_level3_dir: ä¸‰çº§çœŸå®æ ‡ç­¾ç›®å½•  
        level3_labels: ä¸‰çº§æ ‡ç­¾æ–‡ä»¶åˆ—è¡¨
    
    Returns:
        float: HDWAæŒ‡æ ‡å€¼
    """
    print(f"\n{'='*20} è®¡ç®—å±‚æ¬¡è·ç¦»åŠ æƒå‡†ç¡®ç‡ {'='*20}")
    
    # æ„å»ºå±‚æ¬¡è·ç¦»çŸ©é˜µ
    max_label = max(max(hierarchy_dict.map_3_to_2.keys()), 8)  # ç¡®ä¿è¦†ç›–æ‰€æœ‰æ ‡ç­¾
    distance_matrix = np.zeros((max_label + 1, max_label + 1), dtype=np.float32)
    
    # å¡«å……è·ç¦»çŸ©é˜µ
    for i in range(max_label + 1):
        for j in range(max_label + 1):
            if i == j:
                distance_matrix[i, j] = 1.0  # å®Œå…¨æ­£ç¡®ï¼Œæƒé‡1.0
            elif i in hierarchy_dict.map_3_to_2 and j in hierarchy_dict.map_3_to_2:
                # æ£€æŸ¥æ˜¯å¦å±äºåŒä¸€äºŒçº§ç±»
                if hierarchy_dict.map_3_to_2[i] == hierarchy_dict.map_3_to_2[j]:
                    distance_matrix[i, j] = 0.5  # åŒäºŒçº§ç±»å†…é”™è¯¯ï¼Œæƒé‡0.5
                else:
                    distance_matrix[i, j] = 0.1  # è·¨äºŒçº§ç±»é”™è¯¯ï¼Œæƒé‡0.1
            else:
                distance_matrix[i, j] = 0.0  # èƒŒæ™¯æˆ–æ— æ•ˆç±»åˆ«é”™è¯¯ï¼Œæƒé‡0.0
    
    total_weighted_score = 0.0
    total_pixels = 0
    processed_files = 0
    
    for label_path in tqdm(level3_labels, desc="è®¡ç®—HDWA"):
        pred_path = pred_level3_dir / label_path.name
        
        if not pred_path.exists():
            continue
            
        # è¯»å–å›¾åƒ
        pred = cv2.imread(str(pred_path), cv2.IMREAD_GRAYSCALE)
        label = cv2.imread(str(label_path), cv2.IMREAD_GRAYSCALE)
        
        if pred is None or label is None or pred.shape != label.shape:
            continue
        
        # è®¡ç®—åŠ æƒå‡†ç¡®ç‡
        pred_flat = pred.ravel()
        label_flat = label.ravel()
        
        # ä½¿ç”¨è·ç¦»çŸ©é˜µè®¡ç®—æƒé‡
        weights = distance_matrix[label_flat, pred_flat]
        total_weighted_score += np.sum(weights)
        total_pixels += len(weights)
        processed_files += 1
    
    hdwa_score = total_weighted_score / total_pixels if total_pixels > 0 else 0.0
    print(f"å¤„ç†æ–‡ä»¶æ•°: {processed_files}")
    print(f"æ€»åƒç´ æ•°: {total_pixels:,}")
    print(f"å±‚æ¬¡è·ç¦»åŠ æƒå‡†ç¡®ç‡ (HDWA): {hdwa_score:.4f}")
    
    return hdwa_score

def calculate_hierarchical_iou(pred_level2_dir, pred_level3_dir, label_level2_dir, label_level3_dir, level3_labels):
    """
    è®¡ç®—å±‚æ¬¡IoU (Hierarchical IoU, HIoU)
    
    åœ¨æ¯ä¸ªå±‚æ¬¡ä¸Šåˆ†åˆ«è®¡ç®—IoUï¼Œç„¶åæŒ‰é‡è¦æ€§åŠ æƒå¹³å‡
    
    Args:
        pred_level2_dir: äºŒçº§é¢„æµ‹ç»“æœç›®å½•
        pred_level3_dir: ä¸‰çº§é¢„æµ‹ç»“æœç›®å½•
        label_level2_dir: äºŒçº§çœŸå®æ ‡ç­¾ç›®å½•
        label_level3_dir: ä¸‰çº§çœŸå®æ ‡ç­¾ç›®å½•
        level3_labels: ä¸‰çº§æ ‡ç­¾æ–‡ä»¶åˆ—è¡¨
    
    Returns:
        tuple: (HIoUå¾—åˆ†, äºŒçº§mIoU, ä¸‰çº§mIoU)
    """
    print(f"\n{'='*20} è®¡ç®—å±‚æ¬¡IoU {'='*20}")
    
    def compute_miou_for_level(pred_dir, label_dir, labels, level_name):
        """è®¡ç®—å•ä¸ªå±‚æ¬¡çš„mIoU"""
        conf_matrix = {}
        
        for label_path in labels:
            pred_path = pred_dir / label_path.name
            if not pred_path.exists():
                continue
                
            pred = cv2.imread(str(pred_path), cv2.IMREAD_GRAYSCALE)
            if level_name == "äºŒçº§":
                label = cv2.imread(str(label_dir / label_path.name), cv2.IMREAD_GRAYSCALE)
            else:  # ä¸‰çº§
                label = cv2.imread(str(label_path), cv2.IMREAD_GRAYSCALE)
                
            if pred is None or label is None or pred.shape != label.shape:
                continue
            
            # ç´¯ç§¯æ··æ·†çŸ©é˜µ
            unique_labels = np.unique(np.concatenate([pred.ravel(), label.ravel()]))
            for class_id in unique_labels:
                if class_id not in conf_matrix:
                    conf_matrix[class_id] = {'tp': 0, 'fp': 0, 'fn': 0}
                
                pred_mask = (pred == class_id)
                label_mask = (label == class_id)
                
                conf_matrix[class_id]['tp'] += np.sum(pred_mask & label_mask)
                conf_matrix[class_id]['fp'] += np.sum(pred_mask & ~label_mask)
                conf_matrix[class_id]['fn'] += np.sum(~pred_mask & label_mask)
        
        # è®¡ç®—æ¯ç±»IoU
        ious = []
        for class_id, metrics in conf_matrix.items():
            if class_id == 0:  # è·³è¿‡èƒŒæ™¯ç±»
                continue
            tp, fp, fn = metrics['tp'], metrics['fp'], metrics['fn']
            iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0
            ious.append(iou)
        
        return np.mean(ious) if ious else 0.0
    
    # è®¡ç®—äºŒçº§å’Œä¸‰çº§çš„mIoU
    level2_labels = [label_level2_dir / lp.name for lp in level3_labels]
    miou_level2 = compute_miou_for_level(pred_level2_dir, label_level2_dir, level2_labels, "äºŒçº§")
    miou_level3 = compute_miou_for_level(pred_level3_dir, label_level3_dir, level3_labels, "ä¸‰çº§")
    
    # åŠ æƒå¹³å‡ (å¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´æƒé‡)
    weight_level2 = 0.4  # äºŒçº§æƒé‡
    weight_level3 = 0.6  # ä¸‰çº§æƒé‡
    hiou_score = weight_level2 * miou_level2 + weight_level3 * miou_level3
    
    print(f"äºŒçº§mIoU: {miou_level2:.4f}")
    print(f"ä¸‰çº§mIoU: {miou_level3:.4f}")
    print(f"å±‚æ¬¡IoU (HIoU): {hiou_score:.4f} (æƒé‡: äºŒçº§{weight_level2}, ä¸‰çº§{weight_level3})")
    
    return hiou_score, miou_level2, miou_level3

def calculate_error_severity_score(pred_level3_dir, label_level3_dir, level3_labels):
    """
    è®¡ç®—é”™è¯¯ä¸¥é‡æ€§è¯„åˆ† (Error Severity Score, ESS)
    
    æ ¹æ®é”™è¯¯ç±»å‹åˆ†é…ä¸åŒæƒé‡ï¼š
    - å®Œå…¨æ­£ç¡®: 1.0
    - åŒäºŒçº§ç±»å†…é”™è¯¯: 0.6
    - è·¨äºŒçº§ç±»é”™è¯¯: 0.2
    - èƒŒæ™¯é”™è¯¯: 0.0
    
    Args:
        pred_level3_dir: ä¸‰çº§é¢„æµ‹ç»“æœç›®å½•
        label_level3_dir: ä¸‰çº§çœŸå®æ ‡ç­¾ç›®å½•
        level3_labels: ä¸‰çº§æ ‡ç­¾æ–‡ä»¶åˆ—è¡¨
    
    Returns:
        tuple: (ESSå¾—åˆ†, é”™è¯¯ç±»å‹ç»Ÿè®¡)
    """
    print(f"\n{'='*20} è®¡ç®—é”™è¯¯ä¸¥é‡æ€§è¯„åˆ† {'='*20}")
    
    error_stats = {
        'correct': 0,           # å®Œå…¨æ­£ç¡®
        'intra_class': 0,       # åŒäºŒçº§ç±»å†…é”™è¯¯
        'inter_class': 0,       # è·¨äºŒçº§ç±»é”™è¯¯
        'background': 0         # èƒŒæ™¯é”™è¯¯
    }
    
    total_score = 0.0
    total_pixels = 0
    processed_files = 0
    
    for label_path in tqdm(level3_labels, desc="è®¡ç®—ESS"):
        pred_path = pred_level3_dir / label_path.name
        
        if not pred_path.exists():
            continue
            
        pred = cv2.imread(str(pred_path), cv2.IMREAD_GRAYSCALE)
        label = cv2.imread(str(label_path), cv2.IMREAD_GRAYSCALE)
        
        if pred is None or label is None or pred.shape != label.shape:
            continue
        
        pred_flat = pred.ravel()
        label_flat = label.ravel()
        
        # åˆ†ç±»é”™è¯¯ç±»å‹
        for p, l in zip(pred_flat, label_flat):
            if p == l:
                error_stats['correct'] += 1
                total_score += 1.0
            elif l == 0 or p == 0:  # æ¶‰åŠèƒŒæ™¯çš„é”™è¯¯
                error_stats['background'] += 1
                total_score += 0.0
            elif (l in hierarchy_dict.map_3_to_2 and p in hierarchy_dict.map_3_to_2 and
                  hierarchy_dict.map_3_to_2[l] == hierarchy_dict.map_3_to_2[p]):
                error_stats['intra_class'] += 1  # åŒäºŒçº§ç±»å†…é”™è¯¯
                total_score += 0.6
            else:
                error_stats['inter_class'] += 1  # è·¨äºŒçº§ç±»é”™è¯¯
                total_score += 0.2
            
            total_pixels += 1
        
        processed_files += 1
    
    ess_score = total_score / total_pixels if total_pixels > 0 else 0.0
    
    print(f"å¤„ç†æ–‡ä»¶æ•°: {processed_files}")
    print(f"æ€»åƒç´ æ•°: {total_pixels:,}")
    print(f"é”™è¯¯ç±»å‹ç»Ÿè®¡:")
    print(f"  å®Œå…¨æ­£ç¡®: {error_stats['correct']:,} ({error_stats['correct']/total_pixels*100:.2f}%)")
    print(f"  åŒç±»å†…é”™è¯¯: {error_stats['intra_class']:,} ({error_stats['intra_class']/total_pixels*100:.2f}%)")
    print(f"  è·¨ç±»é”™è¯¯: {error_stats['inter_class']:,} ({error_stats['inter_class']/total_pixels*100:.2f}%)")
    print(f"  èƒŒæ™¯é”™è¯¯: {error_stats['background']:,} ({error_stats['background']/total_pixels*100:.2f}%)")
    print(f"é”™è¯¯ä¸¥é‡æ€§è¯„åˆ† (ESS): {ess_score:.4f}")
    
    return ess_score, error_stats

def calculate_semantic_consistency(pred_level3_dir, level3_labels):
    """
    è®¡ç®—è¯­ä¹‰ä¸€è‡´æ€§æŒ‡æ ‡ (Semantic Consistency, SC)
    
    è¯„ä¼°é¢„æµ‹ç»“æœåœ¨è¯­ä¹‰å±‚é¢çš„åˆç†æ€§ï¼Œæ£€æŸ¥ç›¸é‚»åƒç´ çš„ç±»åˆ«è½¬æ¢æ˜¯å¦åˆç†
    
    Args:
        pred_level3_dir: ä¸‰çº§é¢„æµ‹ç»“æœç›®å½•
        level3_labels: ä¸‰çº§æ ‡ç­¾æ–‡ä»¶åˆ—è¡¨
    
    Returns:
        float: è¯­ä¹‰ä¸€è‡´æ€§å¾—åˆ†
    """
    print(f"\n{'='*20} è®¡ç®—è¯­ä¹‰ä¸€è‡´æ€§æŒ‡æ ‡ {'='*20}")
    
    # å®šä¹‰åˆç†çš„ç±»åˆ«è½¬æ¢ (åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§)
    # è¿™é‡Œç®€åŒ–ä¸ºåŒäºŒçº§ç±»å†…çš„è½¬æ¢æ˜¯åˆç†çš„
    def is_reasonable_transition(class1, class2):
        if class1 == class2:
            return True
        if (class1 in hierarchy_dict.map_3_to_2 and class2 in hierarchy_dict.map_3_to_2 and
            hierarchy_dict.map_3_to_2[class1] == hierarchy_dict.map_3_to_2[class2]):
            return True
        return False
    
    total_transitions = 0
    reasonable_transitions = 0
    processed_files = 0
    
    for label_path in tqdm(level3_labels, desc="è®¡ç®—è¯­ä¹‰ä¸€è‡´æ€§"):
        pred_path = pred_level3_dir / label_path.name
        
        if not pred_path.exists():
            continue
            
        pred = cv2.imread(str(pred_path), cv2.IMREAD_GRAYSCALE)
        if pred is None:
            continue
        
        h, w = pred.shape
        
        # æ£€æŸ¥æ°´å¹³ç›¸é‚»åƒç´ 
        for i in range(h):
            for j in range(w-1):
                class1, class2 = pred[i, j], pred[i, j+1]
                if is_reasonable_transition(class1, class2):
                    reasonable_transitions += 1
                total_transitions += 1
        
        # æ£€æŸ¥å‚ç›´ç›¸é‚»åƒç´ 
        for i in range(h-1):
            for j in range(w):
                class1, class2 = pred[i, j], pred[i+1, j]
                if is_reasonable_transition(class1, class2):
                    reasonable_transitions += 1
                total_transitions += 1
        
        processed_files += 1
    
    sc_score = reasonable_transitions / total_transitions if total_transitions > 0 else 0.0
    
    print(f"å¤„ç†æ–‡ä»¶æ•°: {processed_files}")
    print(f"æ€»è½¬æ¢æ•°: {total_transitions:,}")
    print(f"åˆç†è½¬æ¢æ•°: {reasonable_transitions:,}")
    print(f"è¯­ä¹‰ä¸€è‡´æ€§ (SC): {sc_score:.4f}")
    
    return sc_score

def calculate_metrics(label_dir, pred_dir, level_name=""):
    print(f"\n{'='*20} {level_name} æ ‡ç­¾è¯„ä¼° {'='*20}")
    labels, preds = pair_paths(label_dir, pred_dir)
    
    if not labels:
        print(f"è­¦å‘Šï¼š{level_name}æ ‡ç­¾è·¯å¾„ {label_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return

    # ---------- Pass-1ï¼šç»Ÿè®¡çœŸå®å‡ºç°çš„ç±»åˆ« ----------
    label_set = set()
    for lp, pp in tqdm(zip(labels, preds), total=len(labels), desc=f"æ‰«æ{level_name}ç±»åˆ«"):
        if not pp.exists():
            print(f"è­¦å‘Šï¼šé¢„æµ‹æ–‡ä»¶ {pp} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
            
        gt  = cv2.imread(str(lp), cv2.IMREAD_GRAYSCALE)
        pd  = cv2.imread(str(pp), cv2.IMREAD_GRAYSCALE)
        label_set.update(np.unique(gt))
        label_set.update(np.unique(pd))

    class_numbers = sorted(label_set)          # ä¾‹å¦‚ [0,1,2,5]
    classNum      = len(class_numbers)         # 4
    print(f"ç±»åˆ«æ•°é‡: {classNum}")
    print(f"ç±»åˆ«ç¼–å·: {class_numbers}")

    # ---------- å»ºç«‹"åŸæ ‡ç­¾å€¼ â†’ è¿ç»­ç´¢å¼•"æ˜ å°„ ----------
    max_val = max(class_numbers)
    mapping = np.full(max_val + 1, -1, dtype=np.int32)
    for idx, v in enumerate(class_numbers):
        mapping[v] = idx            # e.g. 0â†’0, 1â†’1, 2â†’2, 5â†’3

    # ---------- Pass-2ï¼šç´¯ç§¯æ··æ·†çŸ©é˜µ ----------
    def read_and_bincount(args):
        lp, pp, map_arr, k = args
        if not pp.exists():
            return np.zeros(k*k, dtype=np.int64)
            
        gt = map_arr[cv2.imread(str(lp), cv2.IMREAD_GRAYSCALE)].ravel()
        pd = map_arr[cv2.imread(str(pp), cv2.IMREAD_GRAYSCALE)].ravel()
        return np.bincount(k * gt + pd, minlength=k*k)

    conf_mat = np.zeros((classNum, classNum), dtype=np.int64)
    mapping_arr = mapping                         # ç»™çº¿ç¨‹ç”¨ä¸€ä¸ªåªè¯»å‰¯æœ¬

    t0 = time.time()
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        iterator = ex.map(read_and_bincount,
                        [(lp, pp, mapping_arr, classNum) for lp, pp in zip(labels, preds)])
        for local in tqdm(iterator, total=len(labels), desc=f"è®¡ç®—{level_name}æ··æ·†çŸ©é˜µ"):
            conf_mat += local.reshape(classNum, classNum)
    print(f"ç´¯ç§¯å®Œæˆï¼Œç”¨æ—¶ {time.time()-t0:.1f}s")

    # ---------- æŒ‡æ ‡ ----------
    diag   = np.diag(conf_mat).astype(np.float64)
    sum_r  = conf_mat.sum(axis=1).astype(np.float64)
    sum_c  = conf_mat.sum(axis=0).astype(np.float64)
    total  = conf_mat.sum()

    with np.errstate(divide='ignore', invalid='ignore'):
        precision = np.nan_to_num(diag / sum_c)
        recall    = np.nan_to_num(diag / sum_r)
        f1        = np.nan_to_num(2 * precision * recall / (precision + recall))
        iou       = np.nan_to_num(diag / (sum_r + sum_c - diag))

    oa    = diag.sum() / total
    miou  = np.nanmean(iou)
    freq  = sum_r / total
    fwiou = (freq * iou).sum()
    pe    = (sum_r @ sum_c) / total**2
    kappa = (oa - pe) / (1 - pe)

    # ---------- è¾“å‡º ----------
    np.set_printoptions(precision=4, suppress=True)
    print(f"\n{level_name}æ··æ·†çŸ©é˜µ:\n", conf_mat)
    print(f"{level_name}Precision:", precision)
    print(f"{level_name}Recall:   ", recall)
    print(f"{level_name}F1-score: ", f1)
    print(f"{level_name}IoU:      ", iou)
    print(f"{level_name}OA={oa:.4f}, mIoU={miou:.4f}, FWIoU={fwiou:.4f}, Kappa={kappa:.4f}")
    
    # ä¿å­˜æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡åˆ°CSV
    class_metrics = np.column_stack((precision, recall, f1, iou))
    np.savetxt(f"metrics_{level_name}.csv", class_metrics, delimiter=",", 
               header="Precision,Recall,F1,IoU", comments="",
               fmt="%.4f")
    
    overall_metrics = np.array([oa, miou, fwiou, kappa])
    with open(f"metrics_{level_name}.csv", 'a') as f:
        f.write("\nOverall Metrics\nOA,mIoU,FWIoU,Kappa\n")
        f.write(",".join([f"{m:.4f}" for m in overall_metrics]))
    
    print(f"è¯¦ç»†æŒ‡æ ‡å·²ä¿å­˜åˆ° metrics_{level_name}.csv")
    
    return oa, miou, fwiou, kappa

if __name__ == "__main__":
    print("å¼€å§‹è¯„ä¼°åˆ†å‰²ç²¾åº¦...")
    
    # è¯„ä¼°äºŒçº§æ ‡ç­¾
    level2_metrics = calculate_metrics(label_dir_level2, pred_dir_level2, "äºŒçº§")
    
    # è¯„ä¼°ä¸‰çº§æ ‡ç­¾
    level3_metrics = calculate_metrics(label_dir_level3, pred_dir_level3, "ä¸‰çº§")
    
    # è®¡ç®—å±‚æ¬¡ç‰¹å®šæŒ‡æ ‡
    labels_level3, _ = pair_paths(label_dir_level3, pred_dir_level3)
    if labels_level3:
        print(f"\n{'='*60}")
        print("å¼€å§‹è®¡ç®—å±‚æ¬¡ç‰¹å®šæŒ‡æ ‡...")
        print(f"{'='*60}")
        
        # 1. å±‚æ¬¡ä¸€è‡´æ€§æŒ‡æ ‡ (HC)
        hc_score = calculate_hierarchical_consistency(pred_dir_level3, pred_dir_level2, labels_level3)
        
        # 2. å±‚æ¬¡è·ç¦»åŠ æƒå‡†ç¡®ç‡ (HDWA)
        hdwa_score = calculate_hierarchical_distance_weighted_accuracy(pred_dir_level3, label_dir_level3, labels_level3)
        
        # 3. å±‚æ¬¡IoU (HIoU)
        hiou_score, hiou_level2, hiou_level3 = calculate_hierarchical_iou(
            pred_dir_level2, pred_dir_level3, label_dir_level2, label_dir_level3, labels_level3)
        
        # # 4. é”™è¯¯ä¸¥é‡æ€§è¯„åˆ† (ESS)
        # ess_score, error_stats = calculate_error_severity_score(pred_dir_level3, label_dir_level3, labels_level3)
        
        # # 5. è¯­ä¹‰ä¸€è‡´æ€§æŒ‡æ ‡ (SC)
        # sc_score = calculate_semantic_consistency(pred_dir_level3, labels_level3)
        
        # åˆå§‹åŒ–å˜é‡ä»¥é¿å…NameError
        ess_score = 0.0
        sc_score = 0.0
        error_stats = {'correct': 0, 'intra_class': 0, 'inter_class': 0, 'background': 0}
        
        # ä¿å­˜æ‰€æœ‰å±‚æ¬¡ç‰¹å®šæŒ‡æ ‡
        with open("metrics_hierarchical_all.txt", 'w', encoding='utf-8') as f:
            f.write("å±‚æ¬¡åˆ†ç±»ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡è¯„ä¼°æŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")
            
            f.write("1. å±‚æ¬¡ä¸€è‡´æ€§æŒ‡æ ‡ (Hierarchical Consistency, HC)\n")
            f.write("-"*50 + "\n")
            f.write("å®šä¹‰: ä¸‰çº§é¢„æµ‹æ˜ å°„åˆ°äºŒçº§åä¸äºŒçº§é¢„æµ‹çš„ä¸€è‡´æ€§\n")
            f.write("å…¬å¼: HC = ä¸€è‡´åƒç´ æ•° / æ€»åƒç´ æ•°\n")
            f.write("å–å€¼èŒƒå›´: [0, 1], 1è¡¨ç¤ºå®Œå…¨ä¸€è‡´\n")
            f.write(f"å¾—åˆ†: {hc_score:.4f}\n\n")
            
            f.write("2. å±‚æ¬¡è·ç¦»åŠ æƒå‡†ç¡®ç‡ (Hierarchical Distance Weighted Accuracy, HDWA)\n")
            f.write("-"*50 + "\n")
            f.write("å®šä¹‰: æ ¹æ®é¢„æµ‹é”™è¯¯åœ¨å±‚æ¬¡æ ‘ä¸­çš„è·ç¦»æ¥åŠ æƒçš„å‡†ç¡®ç‡\n")
            f.write("æƒé‡è®¾ç½®: å®Œå…¨æ­£ç¡®=1.0, åŒäºŒçº§ç±»å†…é”™è¯¯=0.5, è·¨äºŒçº§ç±»é”™è¯¯=0.1\n")
            f.write("å–å€¼èŒƒå›´: [0, 1], å€¼è¶Šé«˜è¡¨ç¤ºé”™è¯¯è¶Šè½»å¾®\n")
            f.write(f"å¾—åˆ†: {hdwa_score:.4f}\n\n")
            
            f.write("3. å±‚æ¬¡IoU (Hierarchical IoU, HIoU)\n")
            f.write("-"*50 + "\n")
            f.write("å®šä¹‰: åœ¨æ¯ä¸ªå±‚æ¬¡ä¸Šåˆ†åˆ«è®¡ç®—IoUï¼Œç„¶ååŠ æƒå¹³å‡\n")
            f.write("æƒé‡è®¾ç½®: äºŒçº§=0.4, ä¸‰çº§=0.6\n")
            f.write("å–å€¼èŒƒå›´: [0, 1], ç»¼åˆè€ƒè™‘å„å±‚æ¬¡çš„åˆ†å‰²è´¨é‡\n")
            f.write(f"äºŒçº§mIoU: {hiou_level2:.4f}\n")
            f.write(f"ä¸‰çº§mIoU: {hiou_level3:.4f}\n")
            f.write(f"å±‚æ¬¡IoUå¾—åˆ†: {hiou_score:.4f}\n\n")
            
            f.write("4. é”™è¯¯ä¸¥é‡æ€§è¯„åˆ† (Error Severity Score, ESS)\n")
            f.write("-"*50 + "\n")
            f.write("å®šä¹‰: æ ¹æ®é”™è¯¯ç±»å‹åˆ†é…ä¸åŒæƒé‡çš„ç»¼åˆè¯„åˆ†\n")
            f.write("æƒé‡è®¾ç½®: å®Œå…¨æ­£ç¡®=1.0, åŒç±»å†…é”™è¯¯=0.6, è·¨ç±»é”™è¯¯=0.2, èƒŒæ™¯é”™è¯¯=0.0\n")
            f.write("å–å€¼èŒƒå›´: [0, 1], å€¼è¶Šé«˜è¡¨ç¤ºé”™è¯¯å½±å“è¶Šå°\n")
            f.write("æ³¨æ„: æ­¤æŒ‡æ ‡å½“å‰å·²ç¦ç”¨\n")
            f.write(f"å¾—åˆ†: {ess_score:.4f}\n\n")
            
            f.write("5. è¯­ä¹‰ä¸€è‡´æ€§æŒ‡æ ‡ (Semantic Consistency, SC)\n")
            f.write("-"*50 + "\n")
            f.write("å®šä¹‰: è¯„ä¼°é¢„æµ‹ç»“æœåœ¨ç©ºé—´ä¸Šçš„è¯­ä¹‰åˆç†æ€§\n")
            f.write("è®¡ç®—æ–¹æ³•: æ£€æŸ¥ç›¸é‚»åƒç´ ç±»åˆ«è½¬æ¢çš„åˆç†æ€§\n")
            f.write("å–å€¼èŒƒå›´: [0, 1], å€¼è¶Šé«˜è¡¨ç¤ºç©ºé—´ä¸€è‡´æ€§è¶Šå¥½\n")
            f.write("æ³¨æ„: æ­¤æŒ‡æ ‡å½“å‰å·²ç¦ç”¨\n")
            f.write(f"å¾—åˆ†: {sc_score:.4f}\n\n")
            
            f.write("="*60 + "\n")
            f.write("å±‚æ¬¡ç‰¹å®šæŒ‡æ ‡æ€»ç»“:\n")
            f.write(f"HC (å±‚æ¬¡ä¸€è‡´æ€§):        {hc_score:.4f}\n")
            f.write(f"HDWA (è·ç¦»åŠ æƒå‡†ç¡®ç‡):  {hdwa_score:.4f}\n")
            f.write(f"HIoU (å±‚æ¬¡IoU):        {hiou_score:.4f}\n")
            f.write(f"ESS (é”™è¯¯ä¸¥é‡æ€§):      {ess_score:.4f}\n")
            f.write(f"SC (è¯­ä¹‰ä¸€è‡´æ€§):       {sc_score:.4f}\n")
        
        print(f"\næ‰€æœ‰å±‚æ¬¡ç‰¹å®šæŒ‡æ ‡å·²ä¿å­˜åˆ° metrics_hierarchical_all.txt")
        
        # ä¿å­˜CSVæ ¼å¼çš„æ±‡æ€»æ•°æ®
        hierarchical_metrics = [hc_score, hdwa_score, hiou_score, ess_score, sc_score]
        metric_names = ["HC", "HDWA", "HIoU", "ESS", "SC"]
        
        with open("metrics_hierarchical_summary.csv", 'w', encoding='utf-8') as f:
            f.write("Metric,Score,Description\n")
            f.write(f"HC,{hc_score:.4f},å±‚æ¬¡ä¸€è‡´æ€§\n")
            f.write(f"HDWA,{hdwa_score:.4f},è·ç¦»åŠ æƒå‡†ç¡®ç‡\n")
            f.write(f"HIoU,{hiou_score:.4f},å±‚æ¬¡IoU\n")
            f.write(f"ESS,{ess_score:.4f},é”™è¯¯ä¸¥é‡æ€§è¯„åˆ†\n")
            f.write(f"SC,{sc_score:.4f},è¯­ä¹‰ä¸€è‡´æ€§\n")
        
    else:
        print("\nè­¦å‘Š: æœªæ‰¾åˆ°ä¸‰çº§æ ‡ç­¾æ–‡ä»¶ï¼Œæ— æ³•è®¡ç®—å±‚æ¬¡ç‰¹å®šæŒ‡æ ‡")
        hc_score = hdwa_score = hiou_score = ess_score = sc_score = 0.0
    
    print("\næ‰€æœ‰è¯„ä¼°å®Œæˆï¼")
    
    # è¾“å‡ºæ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ† è¯„ä¼°ç»“æœæ€»ç»“")
    print(f"{'='*60}")
    
    print("\nğŸ“Š ä¼ ç»Ÿåˆ†å‰²æŒ‡æ ‡:")
    if level2_metrics:
        print(f"  äºŒçº§æ ‡ç­¾ - OA: {level2_metrics[0]:.4f}, mIoU: {level2_metrics[1]:.4f}, FWIoU: {level2_metrics[2]:.4f}, Kappa: {level2_metrics[3]:.4f}")
    if level3_metrics:
        print(f"  ä¸‰çº§æ ‡ç­¾ - OA: {level3_metrics[0]:.4f}, mIoU: {level3_metrics[1]:.4f}, FWIoU: {level3_metrics[2]:.4f}, Kappa: {level3_metrics[3]:.4f}")
    
    print("\nğŸ”— å±‚æ¬¡ç‰¹å®šæŒ‡æ ‡:")
    if 'hc_score' in locals():
        print(f"  HC  (å±‚æ¬¡ä¸€è‡´æ€§):       {hc_score:.4f}")
        print(f"  HDWA(è·ç¦»åŠ æƒå‡†ç¡®ç‡):   {hdwa_score:.4f}")
        print(f"  HIoU(å±‚æ¬¡IoU):         {hiou_score:.4f}")
        print(f"  ESS (é”™è¯¯ä¸¥é‡æ€§):      {ess_score:.4f}")
        print(f"  SC  (è¯­ä¹‰ä¸€è‡´æ€§):      {sc_score:.4f}")
    else:
        print("  æœªè®¡ç®—å±‚æ¬¡ç‰¹å®šæŒ‡æ ‡")
    
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"  - metrics_äºŒçº§.csv")
    print(f"  - metrics_ä¸‰çº§.csv")
    if 'hc_score' in locals():
        print(f"  - metrics_hierarchical_all.txt (è¯¦ç»†æŠ¥å‘Š)")
        print(f"  - metrics_hierarchical_summary.csv (æ±‡æ€»æ•°æ®)")
    
    print(f"\n{'='*60}")
    print("âœ… è¯„ä¼°å®Œæˆï¼å±‚æ¬¡åˆ†ç±»ä»»åŠ¡çš„æ‰€æœ‰æŒ‡æ ‡å·²è®¡ç®—å®Œæ¯•ã€‚")
    print(f"{'='*60}")
